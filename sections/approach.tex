\section{Approach}

\AT{We do need to be precise in this section.}

\subsection{Overview}

\AT{WIP: Just jotting some notes down.}

\begin{itemize}
    \item We built a tracer and ran it on a bunch of R code, observing values and their origins. 
    %
    \item The information obtained via tracing is collected in a database equipped with a rich query API. 
    The origins of values can be used reconstruct the calls (in the same manner as previous work~\cite{turcotte2020designing}), and the database of values can be queried to find other potential inputs to functions.
    %
    \item We developed a fuzzer called \tool that takes advantage of this database to construct additional calls with \textit{realistic data} to further exercise functions.
    %
    \item Finally, a data analysis pipeline processes the output of the fuzzer to prepare static type signatures for fuzzed functions.
\end{itemize}

\subsection{Tracer}

\AT{Quickly talk about the tracer.}

\subsection{Database of Values}

The huge amount of R values we have observed during tracing are stored in a custom-written database. 
The values are serialized, along with their \textit{origin} (which package and function are they from, and are they an argument or return value) and some metadata such at their type, or the number of times the value was seen. 
The database also provides a convenient query API; i.e., one may sample values randomly from the database according to some parameters, such as the type \PB{Should we be more precise?}, or by providing an example value on which some characteristics (again, such as the type) can be relaxed.
\AT{We can probably show an example query, and then have a precise list of all potential query parameters after.}

\begin{itemize}
    \item \AT{We need to discuss the relaxation parameters, since those are central to the fuzzing approach.}
    \item \AT{Also discuss the origin tracking, which is important as input to the fuzzer.}
\end{itemize}

\subsection{Fuzzing Technique}

\AT{WIP Draft. 
Extremely a mouthful right now, will edit.}

The fuzzing approach takes advantage of the aforementioned database of values, and is in some sense a variant of mutation-based fuzzing (where instead of mutating arguments to previous calls, new argument values are selected based on previous ones).

The process of choosing arguments to construct new calls to some function $f$ is depicted in Algorithm~\ref{alg:arg-sel}.
In addition to the function $f$ and value database $db$, the algorithm considers how many query parameters to relax on ($numRelax$), as well as all of the previously seen successful calls to $f$ ($succs$).
For each parameter $p$ of $f$, the algorithm determines which parameters to relax on (this may change from one iteration to the next), finds all values that inhabited $p$ in successful calls to $f$, chooses one such value $v$, and queries the database for a value similar to $v$ in all respects, save for the parameters that are being relaxed this time.

This argument selection process is integral to the fuzzing approach itself, depicted in Algorithm~\ref{alg:fuzzer}.
First, the collection of already known successful calls to $f$ is obtained from the database $db$.
The idea in this approach is to start by selecting new arguments essentially at random by querying the database and relaxing on many parameters, and gradually reduce the number of parameters being relaxed as the fuzzer progresses.
In terms of the algorithm, the number of parameters being relaxed is reduced every $tick$, which is determined by dividing the total fuzzing budget by the number of parameters that can be relaxed ($numRelaxParameters$).
The function $f$ will be fuzzed for as long as the budget allows, and initially all database parameters will be relaxed.
The fuzzing itself is straightforward: every $tick$, fewer database parameters are relaxed.
Arguments for a new call to $f$ are generated through the approach depicted in Algorithm~\ref{alg:arg-sel} ($getNewArgs$), the call is performed, and the results are saved in $res$.
If there were no errors, warnings, or crashes, then the successful call is added to the list of successful calls $succs$, and iteration continues until the budget is exhausted.

\input{code-and-figures/approach-algorithms.tex}

\subsubsection{Post-Processing Successful Signatures}

The output of running the fuzzing algorithm is a list of successful calls to a function $f$.
From this list, \textit{call signatures} are extracted by inferring the types of all arguments according to a type system.
Duplicate signatures are discarded, and the list of signatures is simplified by repeatedly attempting to combine two signatures that differ only in one argument type with respect to supplied subtyping rules.
E.g., signatures \code{(int, dbl) => dbl} and \code{(dbl, dbl) => dbl} would be simplified into \code{(dbl, dbl) => dbl}.

\begin{itemize}
    \item \AT{We can try to consolidate signatures in the same way as the Types for R paper does?}
    \item \AT{We're going to look at metadata related to the return value.}
\end{itemize}

\AT{Maybe discussing the type systems here.}